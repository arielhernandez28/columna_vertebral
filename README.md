# columna_vertebral
Este taller colaborativo tiene un enfoque práctico y evaluativo. Aquí, el reto está en tus manos: tú serás el encargado de implementar el proyecto completo. El objetivo es que pongas en práctica las técnicas de preprocesamiento de datos, ingeniería de características, evaluación, ajustes de hiperparámetros y entrenamiento de modelos predictivos supervisados, debes trabajar con tres algoritmos y te propongo los más importantes que exploramos en el curso: KNN, SVC y XGBoost. Sigue los pasos a continuación:

Conformar un equipo de trabajo de máximo dos estudiantes.
Revisar los recursos de aprendizaje de la unidad.
Preprocesar el dataset Download dataset de manera efectiva y analítica:
Carga el dataset proporcionado.
Realiza una inspección inicial de los datos para identificar valores faltantes, columnas relevantes y posibles inconsistencias.
Preprocesa los datos: limpia valores nulos, convierte las variables categóricas a numéricas (si es necesario), y asegúrate de que las variables estén listas para ser alimentadas a los modelos.
Realizar ingeniería de características que pueda mejorar el desempeño de los modelos:
A partir de las variables originales, crea nuevas características que puedan mejorar el desempeño de los modelos. Por ejemplo, puedes crear ratios, transformaciones de variables o combinaciones de columnas que agreguen valor.
Realiza una selección de características: elimina columnas irrelevantes o altamente correlacionadas, y selecciona las características más importantes para el modelo. Realizar escalamiento de las variables, si es necesario numerice. Plantee usar gestión de flujos de trabajo de machine learning con pipelines de Scikit-Learn.
Entrenar los modelos de clasificación (KNN, SVC, XGBoost) y optimizarlos mediante técnicas de tuning de hiperparámetros:
Entrena tres modelos de clasificación supervisada: KNN, SVC y XGBoost.
Ajusta los parámetros de cada modelo para obtener su mejor desempeño. Recuerda que cada modelo tiene diferentes hiperparámetros que se pueden ajustar, como el número de vecinos en KNN, el kernel en SVC, el learning rate y la profundidad en XGBoost. Si es preciso use validación cruzada y k-fold cross-validation.
Realizar el ajuste de hiperparámetros usando técnicas como GridSearchCV o RandomizedSearchCV para optimizar cada modelo. Ajuste los parámetros clave de cada algoritmo para encontrar la combinación que mejore el desempeño.
Evaluar los modelos utilizando métricas de rendimiento como accuracy, precision, recall y F1-score:
Evalúa el rendimiento de cada modelo utilizando las métricas adecuadas, como accuracy, precision, recall, F1-score, y matrices de confusión.
Compara el desempeño de los tres modelos utilizando estas métricas. Recuerda que un modelo puede ser más preciso pero menos sensible, y otro puede ser más equilibrado.
Seleccionar el mejor modelo basado en los resultados obtenidos:
Selecciona el modelo con el mejor rendimiento basado en las métricas de evaluación.
Justifica tu elección: ¿Por qué crees que este modelo es el más adecuado para este conjunto de datos?
Finalmente, envía por correo el enlace de google colab con los permisos de edición con la solución del taller  para que el profesor revise tu actividad. De manera adicional, subes el archivo *.ipynb con la solución al correo.
